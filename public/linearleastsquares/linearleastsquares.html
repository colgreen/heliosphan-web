<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Linear Least Squares</title>
    <meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=0.75"/>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_HTMLorMML-full"></script>
    <link rel="stylesheet" href="../stuff.css" type="text/css" media="screen"/>
    <!-- Google Analytics -->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date(); a = s.createElement(o),
            m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-64605921-1', 'auto');
        ga('send', 'pageview');
    </script>
  </head>
  <body>
    <div class="bannercolumn">
        <a href="../index.html">
            <img src="../banner_v5_thin.jpg" style="display: block; border-radius: 6px" alt="Welcome to Heliosphan" />
        </a>
    </div>
    <div class="articlebodyouter">
      <div class="articlebodyinner">
        <br/>
        <h1 align="center">Linear Least Squares</h1>
        <h4 align="center">Colin Green, October, 2012</h4>
        <br />
        <br />
        Task: Given a set of points in 2D euclidean space, find the line that minimises squared error. A line is described by:
        <br />
        <br />        
        &nbsp;&nbsp;&nbsp;<span style="font-family: Courier New;font-weight: bold">y = mx + c</span><br />
        <br />   
        <p>
        Therefore we wish to find the values of <span style="font-family: Courier New;font-weight: bold">m</span> and 
        <span style="font-family: Courier New;font-weight: bold">c</span> that minimise squared error. The first step is
        to consider squared error as a function of <span style="font-family: Courier New;font-weight: bold">m</span> and 
        <span style="font-family: Courier New;font-weight: bold">c</span>. I'll denote squared error with E<sup>2</sup>.</p>
        &nbsp;&nbsp;&nbsp;<span style="font-family: Courier New;font-weight: bold">E<sup>2</sup> = f(m,c)</span><br />
        <br/>
        <p>So <b>E<sup>2</sup></b> is a 2D surface described by the above function. Due to the nature of squared error we know that the
        surface happens to be a convex function (bowl shaped) with a single minimum point. Therefore we can find that mimimum
        point by finding the single (m,c) coordinate where the function's gradient is zero.
        </p>
        <p>So we need to obtain the gradient function and solve for a gradient of zero (see derivation below). Doing so gives the 
        following functions for <span style="font-family: Courier New;font-weight: bold">m</span> and 
        <span style="font-family: Courier New;font-weight: bold">c</span> respectively:</p>

        <br />
        <table border=0 cellspacing=0 cellpadding=0 width="50%" align=center style="font-size:x-large">
        <tr><td width="50%"></td>
        <td><p>`m = (n sum_i(x_i y_i) - sum_i(x_i) sum_i(y_i)) / (n sum_i(x_i^2) - sum_i(x_i)^2)`</p></td>
        <td width="50%"></td>
        <td nowrap>(1)</td>
        </tr>
        </table>
        <br />
        <br />
        <table border=0 cellspacing=0 cellpadding=0 width="50%" align=center style="font-size:x-large">
        <tr><td width="50%"></td>
        <td><p>`c = (sum_i(x_i) sum_i(x_i y_i) - sum_i(x_i^2) sum_i(y_i)) / (sum_i(x_i)^2 - n sum_i(x_i^2))`</p></td>
        <td width="50%"></td>
        <td nowrap>(2)</td>
        </tr>
        </table>
        <br />
        <br />
        <p>When evaluating the above functions be sure to evaluate the numerator term first and check for a zero, this avoids having to evaluate the denominator and also divide by zero errors.</p>
        <b>Derivation - Page 1</b>
        <br/>
        <br/>
        <div style="text-align:center;">
          <img src="linearleastsquares_pg1.png" alt="linear least squares, derivation, page1" style="border:1px solid black"/>
        </div>
        <br />
        <br />
        <br />
        <br />
        <b>Derivation - Page 2</b>
        <br/>
        <br/>
        <div style="text-align:center;">
          <img src="linearleastsquares_pg2.png" alt="linear least squares, derivation, page1" style="border:1px solid black"/>
        </div>
        <br />
        <br />
        <br />
        <br />
        <div>
          <img src="../creativecommons88x31.png" border="0" align="left" hspace="10" vspace="0" />
          Copyright 2012 Colin Green.<br/>
          This article is licensed under a <a href="http://creativecommons.org/licenses/by/3.0/" rel="nofollow">
            Creative Commons
            Attribution 3.0 License
          </a>
          <br/>
          <br/>
        </div>
      </div>
    </div>
  </body>
</html>